{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef4acc6d",
   "metadata": {},
   "source": [
    "# Tourism Sentiment Analysis - TripAdvisor NYC Data Extraction\n",
    "\n",
    "**Project:** Tourism Sentiment Analysis\n",
    "\n",
    "**Task:** Data Extraction & Processing\n",
    "\n",
    "**Dataset Source:** TripAdvisor (SciDB)\n",
    "\n",
    "**Focus:** NYC, 2022-2025, Hotels\n",
    "\n",
    "**Source URL:** https://www.scidb.cn/en/file?fid=df2d477ee4830d106a58c14053a57b07"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b338d0f3",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration\n",
    "*Import libraries, set up project paths, create directory structure*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0921703a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/db/code/tourism_data_project\n",
      "Bronze base: /Users/db/code/tourism_data_project/data/bronze/tripadvisor\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Set up project paths with bronze subfolder structure\n",
    "project_root = Path(\"../../../../\").resolve()\n",
    "bronze_base = project_root / \"data\" / \"bronze\" / \"tripadvisor\"\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Bronze base: {bronze_base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5010a5fd",
   "metadata": {},
   "source": [
    "## 2. Data Acquisition\n",
    "*Download raw Excel file from ScienceDB using discovered direct API*\n",
    "\n",
    "<details>\n",
    "<summary><strong>Manual Download Instructions</strong> (click to expand)</summary>\n",
    "\n",
    "If automated download fails:\n",
    "1. Visit: https://www.scidb.cn/en/file?fid=df2d477ee4830d106a58c14053a57b07\n",
    "2. Download file manually\n",
    "3. Rename to: `tripadvisor_nyc_2022_2025_original.xlsx`\n",
    "4. Place in: `data/bronze/tripadvisor/00_original_download/`\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a506b8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from: https://china.scidb.cn/download?fileId=df2d477ee4830d106a58c14053a57b07...\n",
      "Download complete: /Users/db/code/tourism_data_project/data/bronze/tripadvisor/00_original_download/tripadvisor_nyc_2022_2025_original.xlsx\n",
      "File size: 156.9 MB\n"
     ]
    }
   ],
   "source": [
    "# Set up download directory\n",
    "original_dir = bronze_base / \"00_original_download\"\n",
    "original_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Direct download URL (SciDB.cn pattern)\n",
    "file_id = \"df2d477ee4830d106a58c14053a57b07\"\n",
    "url = f\"https://china.scidb.cn/download?fileId={file_id}\"\n",
    "file_name = \"tripadvisor_nyc_2022_2025_original.xlsx\"\n",
    "file_path = original_dir / file_name\n",
    "\n",
    "# Download the file\n",
    "if not file_path.exists():\n",
    "    print(f\"Downloading from: {url}...\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    with open(file_path, 'wb') as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "    print(f\"Download complete: {file_path}\")\n",
    "else:\n",
    "    print(f\"File already exists: {file_path}\")\n",
    "\n",
    "# Check file size\n",
    "file_size = file_path.stat().st_size / (1024 * 1024)\n",
    "print(f\"File size: {file_size:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7169ca5",
   "metadata": {},
   "source": [
    "## 3. Bronze Layer: Raw Data Processing\n",
    "*Convert Excel to chunked parquet files preserving original structure*\n",
    "\n",
    "**Input:** `00_original_download/tripadvisor_nyc_2022_2025_original.xlsx` (156.9 MB)\n",
    "\n",
    "**Output:** `01_raw_conversion/tripadvisor_nyc_raw_chunk_*.parquet` (chunked files)\n",
    "\n",
    "**Processing:** 5,000-row chunks for memory efficiency\n",
    "\n",
    "**Purpose:** Preserve complete dataset structure while converting to analysis-friendly format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e75088e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Excel file...\n",
      "Columns found: 15\n",
      "Converting to parquet chunks...\n",
      "Processed 10 chunks...\n",
      "Processed 20 chunks...\n",
      "Processed 30 chunks...\n",
      "Processed 40 chunks...\n",
      "Processed 50 chunks...\n",
      "Processed 60 chunks...\n",
      "Processed 70 chunks...\n",
      "Processed 80 chunks...\n",
      "Conversion complete. Total chunks: 84\n",
      "Output location: /Users/db/code/tourism_data_project/data/bronze/tripadvisor/01_raw_conversion\n"
     ]
    }
   ],
   "source": [
    "# Set up conversion output directory\n",
    "conversion_dir = bronze_base / \"01_raw_conversion\"\n",
    "conversion_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Loading Excel file...\")\n",
    "wb = load_workbook(file_path, read_only=True)\n",
    "ws = wb.active\n",
    "header = [str(cell.value) if cell.value is not None else f\"col_{i}\" for i, cell in enumerate(next(ws.iter_rows(min_row=1, max_row=1)))]\n",
    "print(f\"Columns found: {len(header)}\")\n",
    "\n",
    "# Convert to parquet chunks\n",
    "chunk_size = 5000\n",
    "rows = []\n",
    "part = 0\n",
    "\n",
    "print(\"Converting to parquet chunks...\")\n",
    "for row in ws.iter_rows(min_row=2, values_only=True):\n",
    "    row = list(row[:len(header)])  # truncate any extra columns\n",
    "    while len(row) < len(header):  # fill missing columns with None\n",
    "        row.append(None)\n",
    "    rows.append(row)\n",
    "\n",
    "    if len(rows) >= chunk_size:\n",
    "        df = pd.DataFrame(rows, columns=header)\n",
    "        chunk_filename = f\"tripadvisor_nyc_raw_chunk_{part:05d}.parquet\"\n",
    "        pq.write_table(pa.Table.from_pandas(df), conversion_dir / chunk_filename, compression=\"snappy\")\n",
    "        rows = []\n",
    "        part += 1\n",
    "\n",
    "        # Progress indicator every 10 files\n",
    "        if part % 10 == 0:\n",
    "            print(f\"Processed {part} chunks...\")\n",
    "\n",
    "# Write remaining rows\n",
    "if rows:\n",
    "    df = pd.DataFrame(rows, columns=header)\n",
    "    chunk_filename = f\"tripadvisor_nyc_raw_chunk_{part:05d}.parquet\"\n",
    "    pq.write_table(pa.Table.from_pandas(df), conversion_dir / chunk_filename, compression=\"snappy\")\n",
    "\n",
    "print(f\"Conversion complete. Total chunks: {part + 1}\")\n",
    "print(f\"Output location: {conversion_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99006e46",
   "metadata": {},
   "source": [
    "## 4. Data Verification & Column Inspection\n",
    "*Load converted data to verify structure and examine columns before filtering*\n",
    "\n",
    "**Purpose:** Confirm parquet conversion preserved data integrity  \n",
    "**Check:** Column names, data types, row counts  \n",
    "**Next:** Identify date column format for primary filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "743740c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample chunk shape: (5000, 15)\n",
      "Columns (15):\n",
      "   1. col_0\n",
      "   2. Unnamed: 0\n",
      "   3. hotel_name\n",
      "   4. id_review\n",
      "   5. title\n",
      "   6. date\n",
      "   7. location\n",
      "   8. user_name\n",
      "   9. user_link\n",
      "  10. date_of_stay\n",
      "  11. rating\n",
      "  12. review\n",
      "  13. rating_review\n",
      "  14. n_review_user\n",
      "  15. n_votes_review\n",
      "\n",
      " Data types:\n",
      "col_0              int64\n",
      "Unnamed: 0         int64\n",
      "hotel_name        object\n",
      "id_review          int64\n",
      "title             object\n",
      "date              object\n",
      "location          object\n",
      "user_name         object\n",
      "user_link         object\n",
      "date_of_stay      object\n",
      "rating             int64\n",
      "review            object\n",
      "rating_review      int64\n",
      "n_review_user      int64\n",
      "n_votes_review     int64\n",
      "dtype: object\n",
      "\n",
      " First few rows:\n",
      "   col_0  Unnamed: 0                        hotel_name  id_review  \\\n",
      "0      0           0  Premier Inn London Holborn hotel  877377326   \n",
      "1      1           1  Premier Inn London Holborn hotel  831115773   \n",
      "2      2           2  Premier Inn London Holborn hotel  877070098   \n",
      "\n",
      "                         title      date                     location  \\\n",
      "0  Good room but some concerns     Feb 3                         None   \n",
      "1               Great location  Mar 2022  Bournemouth, United Kingdom   \n",
      "2                   Great stay  Jan 2023  Cleckheaton, United Kingdom   \n",
      "\n",
      "    user_name            user_link    date_of_stay  rating  \\\n",
      "0    Diner135    /Profile/Diner135   February 2023      30   \n",
      "1     Jerry H   /Profile/JerryH836      March 2022      50   \n",
      "2  sunholstan  /Profile/sunholstan    January 2023      50   \n",
      "\n",
      "                                              review  rating_review  \\\n",
      "0  A comfy room with nice coffee machine. Staff w...              3   \n",
      "1  Ideal for getting to major West End areas for ...              5   \n",
      "2  Quiet location but so close to the London buzz...              5   \n",
      "\n",
      "   n_review_user  n_votes_review  \n",
      "0             53              44  \n",
      "1             20              28  \n",
      "2            103              34  \n",
      "\n",
      " Date column sample:\n",
      "['Feb 3', 'Mar 2022', 'Jan 2023', 'Jan 2023', 'Jan 2023', 'Jan 2023', 'Jan 2023', 'Jan 2023', 'Jan 2023', 'Jan 2023']\n"
     ]
    }
   ],
   "source": [
    "# Load a sample chunk to verify conversion\n",
    "sample_file = conversion_dir / \"tripadvisor_nyc_raw_chunk_00000.parquet\"\n",
    "df_sample = pd.read_parquet(sample_file)\n",
    "\n",
    "print(f\"Sample chunk shape: {df_sample.shape}\")\n",
    "print(f\"Columns ({len(df_sample.columns)}):\")\n",
    "for i, col in enumerate(df_sample.columns):\n",
    "    print(f\"  {i+1:2d}. {col}\")\n",
    "\n",
    "print(f\"\\n Data types:\")\n",
    "print(df_sample.dtypes)\n",
    "\n",
    "print(f\"\\n First few rows:\")\n",
    "print(df_sample.head(3))\n",
    "\n",
    "# Check date column specifically for filtering strategy\n",
    "if 'date' in df_sample.columns:\n",
    "    print(f\"\\n Date column sample:\")\n",
    "    print(df_sample['date'].head(10).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3e322c",
   "metadata": {},
   "source": [
    "## 5. Primary Filter: Date Range Selection  \n",
    "*Filter reviews to 2022-2025 timeframe and consolidate chunks*\n",
    "\n",
    "**Input:** 84 raw chunks (~500K+ total rows)\n",
    "\n",
    "**Filter Criteria:** Date contains \"2022\", \"2023\", \"2024\", or \"2025\"\n",
    "\n",
    "**Output:** `02_primary_filter/tripadvisor_nyc_2022_2025_date_filtered.parquet`  \n",
    "\n",
    "**Expected Reduction:** ~90% of data (based on original analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9172a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 84 chunks for date filtering...\n",
      "Processed 20/84 chunks...\n",
      "Processed 40/84 chunks...\n",
      "Processed 60/84 chunks...\n",
      "Processed 80/84 chunks...\n",
      "Consolidating filtered chunks...\n",
      "Date filtering complete!\n",
      "Original chunks: 84\n",
      "Filtered rows: 48,992\n",
      "Saved to: /Users/db/code/tourism_data_project/data/bronze/tripadvisor/02_primary_filter/tripadvisor_nyc_2022_2025_date_filtered.parquet\n",
      "File size: 17.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Set up primary filter output directory\n",
    "primary_filter_dir = bronze_base / \"02_primary_filter\"\n",
    "primary_filter_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load all chunks and apply date filter\n",
    "years_keywords = [\"2022\", \"2023\", \"2024\", \"2025\"]\n",
    "chunk_files = sorted(conversion_dir.glob(\"tripadvisor_nyc_raw_chunk_*.parquet\"))\n",
    "\n",
    "print(f\"Processing {len(chunk_files)} chunks for date filtering...\")\n",
    "all_filtered_rows = []\n",
    "\n",
    "for i, chunk_file in enumerate(chunk_files):\n",
    "    df = pd.read_parquet(chunk_file)\n",
    "    date_mask = df[\"date\"].fillna(\"\").apply(lambda x: any(year in str(x) for year in years_keywords))\n",
    "    filtered_df = df[date_mask]\n",
    "    all_filtered_rows.append(filtered_df)\n",
    "\n",
    "    # Progress indicator every 20 files\n",
    "    if (i + 1) % 20 == 0:\n",
    "        print(f\"Processed {i + 1}/{len(chunk_files)} chunks...\")\n",
    "\n",
    "# Consolidate filtered data\n",
    "print(\"Consolidating filtered chunks...\")\n",
    "filtered_df = pd.concat(all_filtered_rows, ignore_index=True)\n",
    "\n",
    "# Save consolidated result\n",
    "output_file = primary_filter_dir / \"tripadvisor_nyc_2022_2025_date_filtered.parquet\"\n",
    "filtered_df.to_parquet(output_file, compression=\"snappy\")\n",
    "\n",
    "print(f\"Date filtering complete!\")\n",
    "print(f\"Original chunks: {len(chunk_files)}\")\n",
    "print(f\"Filtered rows: {len(filtered_df):,}\")\n",
    "print(f\"Saved to: {output_file}\")\n",
    "\n",
    "# File size check\n",
    "file_size_mb = output_file.stat().st_size / (1024*1024)\n",
    "print(f\"File size: {file_size_mb:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0293de",
   "metadata": {},
   "source": [
    "## 6. Refined Filter: Geographic Filtering\n",
    "*Extract NYC hotels using positive filtering approach*\n",
    "\n",
    "**Input:** `02_primary_filter/tripadvisor_nyc_2022_2025_date_filtered.parquet` (48,992 rows)  \n",
    "\n",
    "**Strategy:** \n",
    "1. Positive NYC filtering (hotel names with NYC indicators)\n",
    "2. Manual cleanup of misclassified hotels\n",
    "\n",
    "**Expected Output:** ~12,500 rows, ~125 hotels\n",
    "\n",
    "**Final Location:** `data/silver/tripadvisor/tripadvisor_nyc_2022_2025_final.parquet`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42de744c",
   "metadata": {},
   "source": [
    "### 6A. Exploratory Analysis Section\n",
    "\n",
    "**Purpose:** Show analysis process used to develop filtering strategy\n",
    "\n",
    "**Status:** Optional - Skip to \"7. Final Geographic Filter & Save\" (Cell 19) to run workflow \n",
    "\n",
    "**Contains:** Novel implementation strategies for geographic filtering challenges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b865d11",
   "metadata": {},
   "source": [
    "\n",
    "#### 6A.1 Initial Hotel Name Analysis\n",
    "*Examine hotel name patterns after date filtering*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6c59820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting geographic analysis with: 48,992 rows\n",
      "Unique hotels: 668\n",
      "\n",
      " Top 15 hotels by review count:\n",
      "  â€¢ Park Plaza Westminster Bridge London (749 reviews)\n",
      "  â€¢ Luma Hotel Time Square (712 reviews)\n",
      "  â€¢ The Clermont, Charing Cross (660 reviews)\n",
      "  â€¢ Travelodge London City hotel (616 reviews)\n",
      "  â€¢ Hyatt Grand Central New York (595 reviews)\n",
      "  â€¢ Sea Containers London (465 reviews)\n",
      "  â€¢ Travelodge London Central Waterloo (449 reviews)\n",
      "  â€¢ Travelodge London Greenwich High Road (437 reviews)\n",
      "  â€¢ Hyatt Centric Times Square New York (434 reviews)\n",
      "  â€¢ Hotel Riu Plaza New York Times Square (431 reviews)\n",
      "  â€¢ The Resident Covent Garden (431 reviews)\n",
      "  â€¢ Leonardo Royal London Tower Bridge (418 reviews)\n",
      "  â€¢ Travelodge London Central City Road (409 reviews)\n",
      "  â€¢ Park Grand London Hyde Park (402 reviews)\n",
      "  â€¢ Travelodge London Farringdon (390 reviews)\n",
      "\n",
      " Sample hotel names (checking for international patterns):\n",
      "  â€¢ Park Plaza Westminster Bridge London\n",
      "  â€¢ Luma Hotel Time Square\n",
      "  â€¢ The Clermont, Charing Cross\n",
      "  â€¢ Travelodge London City hotel\n",
      "  â€¢ Hyatt Grand Central New York\n",
      "  â€¢ Sea Containers London\n",
      "  â€¢ Travelodge London Central Waterloo\n",
      "  â€¢ Travelodge London Greenwich High Road\n",
      "  â€¢ Hyatt Centric Times Square New York\n",
      "  â€¢ Hotel Riu Plaza New York Times Square\n",
      "  â€¢ The Resident Covent Garden\n",
      "  â€¢ Leonardo Royal London Tower Bridge\n",
      "  â€¢ Travelodge London Central City Road\n",
      "  â€¢ Park Grand London Hyde Park\n",
      "  â€¢ Travelodge London Farringdon\n",
      "  â€¢ Premier Inn London St Pancras hotel\n",
      "  â€¢ Travelodge London Stratford\n",
      "  â€¢ Park Plaza London Waterloo\n",
      "  â€¢ Travelodge London Tower Bridge\n",
      "  â€¢ Millennium Gloucester Hotel London Kensington\n",
      "  â€¢ Premier Inn London King's Cross Hotel\n",
      "  â€¢ DoubleTree by Hilton Hotel New York Times Square West\n",
      "  â€¢ The Savoy\n",
      "  â€¢ Hyatt Place New York/Chelsea\n",
      "  â€¢ Canopy by Hilton London City\n"
     ]
    }
   ],
   "source": [
    "# Load date-filtered data for geographic analysis\n",
    "primary_filter_dir = bronze_base / \"02_primary_filter\"\n",
    "exploration_df = pd.read_parquet(primary_filter_dir / \"tripadvisor_nyc_2022_2025_date_filtered.parquet\")\n",
    "\n",
    "print(f\"Starting geographic analysis with: {len(exploration_df):,} rows\")\n",
    "print(f\"Unique hotels: {exploration_df['hotel_name'].nunique()}\")\n",
    "\n",
    "# Initial hotel name examination\n",
    "print(f\"\\n Top 15 hotels by review count:\")\n",
    "top_hotels = exploration_df['hotel_name'].value_counts().head(15)\n",
    "for hotel, count in top_hotels.items():\n",
    "    print(f\"  â€¢ {hotel} ({count:,} reviews)\")\n",
    "\n",
    "# Look for obvious non-NYC patterns\n",
    "print(f\"\\n Sample hotel names (checking for international patterns):\")\n",
    "sample_hotels = exploration_df['hotel_name'].value_counts().head(25).index\n",
    "for hotel in sample_hotels:\n",
    "    print(f\"  â€¢ {hotel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2259ed",
   "metadata": {},
   "source": [
    "#### 6A.2 UK Reviewer Concentration Strategy\n",
    "\n",
    "*Approach: Use reviewer location patterns to identify misclassified hotels*\n",
    "\n",
    "**Challenge:** Hotel names alone insufficient (e.g., \"SoHo\" exists in both NYC and London)\n",
    "\n",
    "**Innovation:** Analyze reviewer geographic patterns to detect misclassified hotels\n",
    "\n",
    "**Logic:** London hotels will have high concentrations of UK-based reviewers\n",
    "\n",
    "**Threshold:** Hotels with >60% UK reviewers (min. 10 location entries) flagged for removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29e3217b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing reviewer geographic patterns...\n",
      "Hotels with >60% UK reviewers: 141\n",
      "\n",
      " UK-heavy hotels (likely London):\n",
      "  â€¢ Premier Inn London Hanger Lane hotel - 92.7% UK reviewers (96 total)\n",
      "  â€¢ Fitzrovia Hotel - 90.5% UK reviewers (21 total)\n",
      "  â€¢ Premier Inn London New Southgate Hotel - 90.5% UK reviewers (21 total)\n",
      "  â€¢ The Chamberlain Hotel - 90.0% UK reviewers (30 total)\n",
      "  â€¢ Premier Inn London Archway hotel - 88.1% UK reviewers (109 total)\n",
      "  â€¢ The Luxury Inn - 87.5% UK reviewers (16 total)\n",
      "  â€¢ hub by Premier Inn London Spitalfields, Brick Lane hotel - 85.9% UK reviewers (85 total)\n",
      "  â€¢ Premier Inn London Greenwich hotel - 85.5% UK reviewers (124 total)\n",
      "  â€¢ Premier Inn London Tolworth - 85.5% UK reviewers (62 total)\n",
      "  â€¢ The Prince of Wales - Townhouse - 84.6% UK reviewers (13 total)\n"
     ]
    }
   ],
   "source": [
    "# Analyze reviewer location patterns to identify non-NYC hotels\n",
    "print(\"Analyzing reviewer geographic patterns...\")\n",
    "\n",
    "hotel_stats = []\n",
    "for hotel_name, group in exploration_df.groupby('hotel_name'):\n",
    "    location_data = group['location'].fillna('')\n",
    "\n",
    "    total_reviews = len(group)\n",
    "    total_with_location = group['location'].notna().sum()\n",
    "    uk_reviews = location_data.str.contains('United Kingdom|UK|England|Scotland|Wales', case=False).sum()\n",
    "    shanghai_reviews = location_data.str.contains('Shanghai|China', case=False).sum()\n",
    "\n",
    "    hotel_stats.append({\n",
    "        'hotel_name': hotel_name,\n",
    "        'total_reviews': total_reviews,\n",
    "        'total_with_location': total_with_location,\n",
    "        'uk_reviews': uk_reviews,\n",
    "        'shanghai_reviews': shanghai_reviews\n",
    "    })\n",
    "\n",
    "# Convert to analysis DataFrame\n",
    "hotel_analysis = pd.DataFrame(hotel_stats)\n",
    "hotel_analysis['uk_percentage'] = (hotel_analysis['uk_reviews'] / hotel_analysis['total_with_location']).fillna(0)\n",
    "hotel_analysis['shanghai_percentage'] = (hotel_analysis['shanghai_reviews'] / hotel_analysis['total_with_location']).fillna(0)\n",
    "\n",
    "# Identify problematic hotels\n",
    "uk_threshold = 0.6\n",
    "uk_hotels = hotel_analysis[\n",
    "    (hotel_analysis['uk_percentage'] > uk_threshold) &\n",
    "    (hotel_analysis['total_with_location'] >= 10)\n",
    "]\n",
    "\n",
    "print(f\"Hotels with >{uk_threshold*100:.0f}% UK reviewers: {len(uk_hotels)}\")\n",
    "if len(uk_hotels) > 0:\n",
    "    print(\"\\n UK-heavy hotels (likely London):\")\n",
    "    uk_display = uk_hotels.nlargest(10, 'uk_percentage')[['hotel_name', 'total_with_location', 'uk_percentage']]\n",
    "    for _, row in uk_display.iterrows():\n",
    "        print(f\"  â€¢ {row['hotel_name']} - {row['uk_percentage']:.1%} UK reviewers ({row['total_with_location']} total)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e1fc02",
   "metadata": {},
   "source": [
    "#### 6A.3 Positive NYC Filtering Strategy\n",
    "*Conservative approach: Identify genuine NYC hotels using location indicators*\n",
    "\n",
    "**Strategy Shift:** Instead of removing non-NYC, actively identify NYC hotels\n",
    "\n",
    "**Indicators:** Hotel names containing NYC-specific terms\n",
    "\n",
    "**Advantage:** Reduces false positives from ambiguous neighborhood names (SoHo, Chelsea, etc.)\n",
    "\n",
    "**Final Cleanup:** Manual removal of remaining misclassified hotels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10fd92fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYC hotels identified: 12,846 rows\n",
      "Unique NYC hotels: 127\n",
      "\n",
      " Top 10 NYC hotels:\n",
      "  â€¢ Luma Hotel Time Square (712 reviews)\n",
      "  â€¢ Hyatt Grand Central New York (595 reviews)\n",
      "  â€¢ Hyatt Centric Times Square New York (434 reviews)\n",
      "  â€¢ Hotel Riu Plaza New York Times Square (431 reviews)\n",
      "  â€¢ DoubleTree by Hilton Hotel New York Times Square West (354 reviews)\n",
      "  â€¢ Hyatt Place New York/Chelsea (334 reviews)\n",
      "  â€¢ M Social Hotel Times Square New York (291 reviews)\n",
      "  â€¢ Lotte New York Palace (284 reviews)\n",
      "  â€¢ 1 Hotel Central Park (282 reviews)\n",
      "  â€¢ Arlo Midtown (281 reviews)\n",
      "\n",
      " NYC hotels with ambiguous neighborhood terms:\n",
      "  SoHo: 7 hotels\n",
      "    â€¢ The Soho Hotel\n",
      "    â€¢ hub by Premier Inn London Soho hotel\n",
      "    â€¢ The Z Hotel Soho\n",
      "  Chelsea: 9 hotels\n",
      "    â€¢ SpringHill Suites New York Manhattan/Chelsea\n",
      "    â€¢ TownePlace Suites by Marriott New York Manhattan/Chelsea\n",
      "    â€¢ Hyatt House New York/Chelsea\n"
     ]
    }
   ],
   "source": [
    "# Apply positive NYC filtering - identify genuine NYC hotels\n",
    "nyc_indicators = [\n",
    "    'New York', 'NYC', 'Manhattan', 'Brooklyn', 'Queens', 'Bronx',\n",
    "    'Times Square', 'Time Square', 'Central Park', 'Wall Street',\n",
    "    'Midtown', 'Downtown', 'Financial District', 'SoHo', 'NoMad',\n",
    "    'TriBeCa', 'Upper East', 'Upper West', 'Lower East', 'Herald Square',\n",
    "    'Penn Station', 'Grand Central', 'JFK', 'LaGuardia', 'Empire State'\n",
    "]\n",
    "\n",
    "nyc_pattern = '|'.join(nyc_indicators)\n",
    "nyc_hotels = exploration_df[exploration_df['hotel_name'].str.contains(nyc_pattern, case=False, na=False)]\n",
    "\n",
    "print(f\"NYC hotels identified: {len(nyc_hotels):,} rows\")\n",
    "print(f\"Unique NYC hotels: {nyc_hotels['hotel_name'].nunique()}\")\n",
    "\n",
    "# Check for remaining ambiguous terms that might be misclassified\n",
    "print(f\"\\n Top 10 NYC hotels:\")\n",
    "nyc_top = nyc_hotels['hotel_name'].value_counts().head(10)\n",
    "for hotel, count in nyc_top.items():\n",
    "    print(f\"  â€¢ {hotel} ({count:,} reviews)\")\n",
    "\n",
    "# Check for potentially ambiguous hotels needing manual review\n",
    "ambiguous_terms = ['SoHo', 'Chelsea', 'Greenwich', 'Victoria']\n",
    "print(f\"\\n NYC hotels with ambiguous neighborhood terms:\")\n",
    "for term in ambiguous_terms:\n",
    "    matching = nyc_hotels[nyc_hotels['hotel_name'].str.contains(term, case=False, na=False)]\n",
    "    if len(matching) > 0:\n",
    "        unique_hotels = matching['hotel_name'].unique()\n",
    "        print(f\"  {term}: {len(unique_hotels)} hotels\")\n",
    "        for hotel in unique_hotels[:3]:  # Show first 3\n",
    "            print(f\"    â€¢ {hotel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a2ecce",
   "metadata": {},
   "source": [
    "#### 6A.4 Manual Cleanup of Misclassified Hotels\n",
    "*Remove remaining London hotels caught by ambiguous neighborhood names*\n",
    "\n",
    "**Issue:** \"SoHo\" exists in both NYC and London\n",
    "\n",
    "**Solution:** Remove clearly London-branded hotels\n",
    "\n",
    "**Targets:** Hotels with \"London\" in name or known London hotel chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1687d02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing London hotels:\n",
      "  â€¢ The Soho Hotel (19 reviews)\n",
      "  â€¢ The Z Hotel Soho (38 reviews)\n",
      "  â€¢ hub by Premier Inn London Soho hotel (154 reviews)\n",
      "\n",
      "Manual cleanup complete\n",
      "Final NYC dataset: 12,635 rows\n",
      "Unique hotels: 124\n",
      "\n",
      " Remaining SoHo hotels (verified NYC):\n",
      "  â€¢ Arlo SoHo\n",
      "  â€¢ Courtyard New York Manhattan/SoHo\n",
      "  â€¢ Soho Grand Hotel\n",
      "  â€¢ Sohotel\n"
     ]
    }
   ],
   "source": [
    "# Manual removal of identified London hotels\n",
    "london_hotels_to_remove = [\n",
    "    'The Soho Hotel',           # London SoHo hotel\n",
    "    'The Z Hotel Soho',         # London hotel chain\n",
    "    'hub by Premier Inn London Soho hotel'  # Explicitly London-branded\n",
    "]\n",
    "\n",
    "print(f\"Removing London hotels:\")\n",
    "for hotel in london_hotels_to_remove:\n",
    "    count = nyc_hotels[nyc_hotels['hotel_name'] == hotel].shape[0]\n",
    "    print(f\"  â€¢ {hotel} ({count:,} reviews)\")\n",
    "\n",
    "# Apply manual cleanup\n",
    "final_nyc_df = nyc_hotels[~nyc_hotels['hotel_name'].isin(london_hotels_to_remove)].copy()\n",
    "\n",
    "print(f\"\\nManual cleanup complete\")\n",
    "print(f\"Final NYC dataset: {len(final_nyc_df):,} rows\")\n",
    "print(f\"Unique hotels: {final_nyc_df['hotel_name'].nunique()}\")\n",
    "\n",
    "# Verify remaining SoHo hotels are legitimate NYC hotels\n",
    "remaining_soho = final_nyc_df[final_nyc_df['hotel_name'].str.contains('soho', case=False)]['hotel_name'].unique()\n",
    "print(f\"\\n Remaining SoHo hotels (verified NYC):\")\n",
    "for hotel in remaining_soho:\n",
    "    print(f\"  â€¢ {hotel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c964eae",
   "metadata": {},
   "source": [
    "## 7. Final Geographic Filter & Save\n",
    "\n",
    "*Clean, validated approach - works whether exploration was run or skipped*\n",
    "\n",
    "**Implementation:** Apply proven NYC filter strategy\n",
    "\n",
    "**Output:** `data/silver/tripadvisor/tripadvisor_nyc_2022_2025_final.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86477de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset saved!\n",
      "Location: /Users/db/code/tourism_data_project/data/bronze/tripadvisor/03_refined_filter/tripadvisor_nyc_2022_2025_final.parquet\n",
      "Rows: 12,635\n",
      "Hotels: 124\n",
      "File size: 4.9 MB\n",
      "\n",
      "Ready for gold layer processing and analysis!\n"
     ]
    }
   ],
   "source": [
    "# Load primary filtered data (works whether exploration was run or skipped)\n",
    "primary_filter_dir = bronze_base / \"02_primary_filter\"\n",
    "df_for_filtering = pd.read_parquet(primary_filter_dir / \"tripadvisor_nyc_2022_2025_date_filtered.parquet\")\n",
    "\n",
    "# Apply validated NYC filter strategy\n",
    "nyc_indicators = [\n",
    "    'New York', 'NYC', 'Manhattan', 'Brooklyn', 'Queens', 'Bronx',\n",
    "    'Times Square', 'Time Square', 'Central Park', 'Wall Street',\n",
    "    'Midtown', 'Downtown', 'Financial District', 'SoHo', 'NoMad',\n",
    "    'TriBeCa', 'Upper East', 'Upper West', 'Lower East', 'Herald Square',\n",
    "    'Penn Station', 'Grand Central', 'JFK', 'LaGuardia', 'Empire State'\n",
    "]\n",
    "\n",
    "nyc_pattern = '|'.join(nyc_indicators)\n",
    "nyc_filtered = df_for_filtering[df_for_filtering['hotel_name'].str.contains(nyc_pattern, case=False, na=False)]\n",
    "\n",
    "# Remove identified London hotels\n",
    "london_hotels_to_remove = ['The Soho Hotel', 'The Z Hotel Soho', 'hub by Premier Inn London Soho hotel']\n",
    "final_clean_df = nyc_filtered[~nyc_filtered['hotel_name'].isin(london_hotels_to_remove)].copy()\n",
    "\n",
    "# Save to silver directory (corrected structure)\n",
    "silver_dir = project_root / \"data\" / \"silver\" / \"tripadvisor\"\n",
    "silver_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_file = silver_dir / \"tripadvisor_nyc_2022_2025_final.parquet\"\n",
    "final_clean_df.to_parquet(output_file, compression=\"snappy\")\n",
    "\n",
    "print(f\"Final dataset saved!\")\n",
    "print(f\"Location: {output_file}\")\n",
    "print(f\"Rows: {len(final_clean_df):,}\")\n",
    "print(f\"Hotels: {final_clean_df['hotel_name'].nunique()}\")\n",
    "\n",
    "file_size_mb = output_file.stat().st_size / (1024*1024)\n",
    "print(f\"File size: {file_size_mb:.1f} MB\")\n",
    "print(f\"\\nReady for gold layer processing and analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3ee782",
   "metadata": {},
   "source": [
    "## 8. Final Verification & Cleanup\n",
    "\n",
    "*Verify saved dataset and optional cleanup of intermediate files*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a1bcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Dataset Verification:\n",
      "==================================================\n",
      "File loads successfully\n",
      "Shape: (12635, 15)\n",
      "Unique hotels: 124\n",
      "\n",
      "Column info:\n",
      "   â€¢ Total columns: 15\n",
      "   â€¢ Date range sample: ['Jan 2023', 'Aug 2022', 'Jan 2023']\n",
      "   â€¢ Top 3 hotels:\n",
      "     - Luma Hotel Time Square: 712 reviews\n",
      "     - Hyatt Grand Central New York: 595 reviews\n",
      "     - Hyatt Centric Times Square New York: 434 reviews\n",
      "\n",
      "Known Column Issues (to address in gold layer):\n",
      "   â€¢ Dummy columns found: ['col_0', 'Unnamed: 0']\n",
      "   â€¢ These are Excel conversion artifacts - will be cleaned in gold processing\n",
      "\n",
      "File Storage Summary:\n",
      "   â€¢ Raw chunks (01_raw_conversion): ~169 MB\n",
      "   â€¢ Primary filter (02_primary_filter): 17.7 MB\n",
      "   â€¢ Final dataset (03_refined_filter): 4.9 MB\n",
      "\n",
      "ðŸ§¹ Optional Cleanup:\n",
      "   â€¢ To save disk space, you can delete intermediate processing files:\n",
      "   â€¢ rm -rf /Users/db/code/tourism_data_project/data/bronze/tripadvisor/01_raw_conversion\n",
      "   â€¢ rm -rf /Users/db/code/tourism_data_project/data/bronze/tripadvisor/02_primary_filter\n",
      "   â€¢ Keeps: original Excel + final parquet (161.8 MB total)\n",
      "\n",
      "Workflow complete! Ready for gold layer processing.\n"
     ]
    }
   ],
   "source": [
    "# Load and verify final saved dataset\n",
    "print(\"Final Dataset Verification:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "final_saved = pd.read_parquet(output_file)\n",
    "print(f\"File loads successfully\")\n",
    "print(f\"Shape: {final_saved.shape}\")\n",
    "print(f\"Unique hotels: {final_saved['hotel_name'].nunique()}\")\n",
    "\n",
    "# Quick data quality check\n",
    "print(f\"\\nColumn info:\")\n",
    "print(f\"   â€¢ Total columns: {len(final_saved.columns)}\")\n",
    "print(f\"   â€¢ Date range sample: {final_saved['date'].dropna().head(3).tolist()}\")\n",
    "print(f\"   â€¢ Top 3 hotels:\")\n",
    "for hotel, count in final_saved['hotel_name'].value_counts().head(3).items():\n",
    "    print(f\"     - {hotel}: {count:,} reviews\")\n",
    "\n",
    "# Document known column issues for gold layer processing\n",
    "print(f\"\\nKnown Column Issues (to address in gold layer):\")\n",
    "dummy_columns = [col for col in final_saved.columns if 'Unnamed:' in str(col) or col in ['col_0']]\n",
    "if dummy_columns:\n",
    "    print(f\"   â€¢ Dummy columns found: {dummy_columns}\")\n",
    "    print(f\"   â€¢ These are Excel conversion artifacts - will be cleaned in gold processing\")\n",
    "else:\n",
    "    print(f\"   â€¢ No dummy columns detected\")\n",
    "\n",
    "print(f\"\\nFile Storage Summary:\")\n",
    "conversion_size = sum(f.stat().st_size for f in conversion_dir.glob(\"*.parquet\")) / (1024*1024)\n",
    "primary_filter_size = (bronze_base / \"02_primary_filter\" / \"tripadvisor_nyc_2022_2025_date_filtered.parquet\").stat().st_size / (1024*1024)\n",
    "print(f\"   â€¢ Raw chunks (bronze/01_raw_conversion): ~{conversion_size:.0f} MB\")\n",
    "print(f\"   â€¢ Primary filter (bronze/02_primary_filter): {primary_filter_size:.1f} MB\")\n",
    "print(f\"   â€¢ Final dataset (silver/tripadvisor): {file_size_mb:.1f} MB\")\n",
    "\n",
    "print(f\"\\nOptional Cleanup:\")\n",
    "print(f\"   â€¢ To save disk space, you can delete intermediate processing files:\")\n",
    "print(f\"   â€¢ rm -rf {conversion_dir}\")\n",
    "print(f\"   â€¢ rm -rf {bronze_base}/02_primary_filter\")\n",
    "print(f\"   â€¢ Keeps: original Excel + final silver parquet ({156.9 + file_size_mb:.1f} MB total)\")\n",
    "print(f\"\\nWorkflow complete! Ready for gold layer processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c64361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tourism_data_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
